---
layout: post 
title:  "Apache Flink 1.13.0 Release Announcement"
date: 2021-04-22T08:00:00.000Z 
categories: news 
authors:
- stephan:
  name: "Stephan Ewen"
  twitter: "StephanEwen"
- dwysakowicz:
  name: "Dawid Wysakowicz"
  twitter: "dwysakowicz"

excerpt: The Apache Flink community is excited to announce the release of Flink 1.13.0! Around 200 contributors worked on over 1,000 issues to bring significant improvements to usability and observability as well as new features that improve elasticity of Flink’s Application-style deployments.
---


The Apache Flink community is excited to announce the release of Flink 1.13.0! More than 200
contributors worked on over 1,000 issues for this new version.

The release brings us a big step forward in one of our major efforts: **Making Stream Processing
Applications as natural and as simple to manage as any other application.** The new *reactive scaling*
mode means that scaling streaming applications in and out now works like in any other application,
by just changing the number of parallel processes.

The release also prominently features a **series of improvements that help users better understand the performance of
applications.** When the streams don't flow as fast as you'd hope, these can help you to understand
why: Load and *backpressure visualization* to identify bottlenecks, *CPU flame graphs* to identify hot
code paths in your application, and *State Access Latencies* to see how the State Backends are keeping
up.

Beyond those features, the Flink community has added a ton of improvements all over the system,
some of which we discuss in this article. We hope you enjoy the new release and features.
Towards the end of the article, we describe changes to be aware of when upgrading
from earlier versions of Apache Flink.

{% toc %}

We encourage you to [download the release](https://flink.apache.org/downloads.html) and share your
feedback with the community through
the [Flink mailing lists](https://flink.apache.org/community.html#mailing-lists)
or [JIRA](https://issues.apache.org/jira/projects/FLINK/summary).

## Notable Features and Improvements

### Reactive Scaling

Reactive Scaling is the latest piece in Flink's initiative to make Stream Processing
Applications as natural and as simple to manage as any other application.

Flink has a dual nature when it comes to resource management and deployments: You can deploy
Flink applications onto resource orchestrators like Kubernetes or Yarn in such a way that Flink actively manages
the resources, and allocates and releases workers as needed. That is especially useful for jobs and
applications that rapidly change their required resources, like batch applications and ad-hoc SQL
queries. The application parallelism rules, the number of workers follows. In the context of Flink
applications, we call this *active scaling*.

For long running streaming applications, it is often a nicer model to just deploy them like any
other long-running application: The application doesn't really need to know that it runs on K8s,
EKS, Yarn, etc. and doesn't try to acquire a specific amount of workers; instead, it just uses the
number of workers that is given to it. The number of workers rules, the application parallelism
adjusts to that. In the context of Flink, we call that *re-active scaling*.

The [Application Deployment Mode]({{ site.DOCS_BASE_URL }}flink-docs-release-1.13/docs/concepts/flink-architecture/#flink-application-execution)
started this effort, making deployments more application-like (by avoiding two separate deployment
steps to (1) start cluster and (2) submit application). The reactive scaling mode completes this,
and you now don't have to use extra tools (scripts or a K8s operator) any more to keep the number
of workers and the application parallelism settings in sync.

You can now put an auto-scaler around Flink applications like around other typical applications — as
long as you are mindful about the cost of rescaling, when configuring the autoscaler: Stateful
streaming applications must move state around when scaling.

To try the reactive-scaling mode, add the `scheduler-mode: reactive` config entry and deploy
an application cluster ([standalone]({{ site.DOCS_BASE_URL }}flink-docs-release-1.13/docs/deployment/resource-providers/standalone/overview/#application-mode) or [Kubernetes]({{ site.DOCS_BASE_URL }}flink-docs-release-1.13/docs/deployment/resource-providers/standalone/kubernetes/#deploy-application-cluster)). Check out [the reactive scaling docs]({{ site.DOCS_BASE_URL }}flink-docs-release-1.13/docs/deployment/elastic_scaling/#reactive-mode) for more details.


## Analyzing Application Performance

Like for any application, analyzing and understanding the performance of a Flink application
is critical. Often event more critical, because Flink applications are typically data-intensive
(process high volumes of data) and are at the same time expected to provide results within
(near-) real-time latencies.

When an application doesn't keep up with the data rate any more, or an application takes more
resources than you'd expect it would, these new tools can help you track down the causes:

### Bottleneck detection, Back Pressure Monitoring

The first question during performance analysis is often: Which operation is the bottleneck?

To help answer that, Flink exposes metrics about the degree to which tasks are *busy* (doing work)
and *back-pressured* (have capacity to do work, but cannot, because their successor operators
are cannot accept more results). Candidates for bottlenecks are the busy operators whose predecessors
are back-pressured.

Flink 1.13 brings an improved back pressure metric system (using task mailbox timings, rather than
thread stack sampling) and a reworked graphical representation of the job's dataflow with color coding
and ratios for busyness and back pressure.

<figure style="align-content: center">
  <img src="{{ site.baseurl }}/img/blog/2021-04-xx-release-1.13.0/bottleneck.png" style="width: 900px"/>
</figure>

### CPU flame graphs in Web UI

The next question during performance analysis is typically: What part of work in the bottleneck
operator is expensive?

One visually effective means to investigate that are *Flame Graphs*. They help answer question like:
  - Which methods are currently consuming CPU resources?
  - How does one method's CPU consumption compare to other methods?
  - Which series of calls on the stack led to executing a particular method?
  
Flame Graphs are constructed by repeatedly sampling the thread stack traces. Every method call is
represented by a bar, where the length of the bar is proportional to the number of times it is present
in the samples. When enabled, the graphs are shown in a new UI component for the selected operator.

<figure style="align-content: center">
  <img src="{{ site.baseurl }}/img/blog/2021-04-xx-release-1.13.0/7.png" style="display: block; margin-left: auto; margin-right: auto; width: 600px"/>
</figure>

Flame graphs are expensive to create: They may cause processing overhead and can put a heavy load
on Flink's metric system. Because of that, users need to explicitly enabled them in the configuration.

### Access Latency Metrics for State

Another possibly performance bottleneck can be the state backend, especially when your state is larger
than the main memory available to Flink and you are using the [RocksDB state backend](
{{ site.DOCS_BASE_URL }}flink-docs-release-1.13/docs/ops/state/state_backends/#the-embeddedrocksdbstatebackend).

That's not saying RocksDB is slow (we love RocksDB!), but it has some requirements to achieve
good performance. For example, it is easy to accidentally [starve RocksDB's demand for IOPs on cloud setups with
the wrong type of disk resources](https://www.ververica.com/blog/the-impact-of-disks-on-rocksdb-state-backend-in-flink-a-case-study).

On top of the CPU flame graphs, the new *state backend latency metrics* can help you understand whether
your state backend is responsive. For example, if you see that RocksDB state accesses start to take
milliseconds, you probably need to look into your memory and I/O configuration.
These metrics can be activated by setting the `state.backend.rocksdb.latency-track-enabled` option.
The metrics are sampled and their collection should have a marginal impact on the RocksDB state
backend performance.

### Switching State Backend with savepoints

You can now change the state backend of a Flink application when resuming from a savepoint.
That means the application's state is no longer locked into the state backend that was used when
the application was initially started.

This makes it possible, for example, to initially start with the HashMap State Backend (pure
in-memory in JVM Heap) and later switch to the RocksDB State Backend, once the state grows
too large.

Under the hood, Flink now has a canonical savepoint format, which all state backends use when
creating a data snapshot for a savepoint.

### Support user-specified pod templates for Active Kubernetes Deployments

The native Kubernetes deployment received an important update that it supports custom pod templates.
Flink from now on allows users to define the JobManager and TaskManager pods via template files.
This allows to support advanced features that are not supported by Flink Kubernetes config options
directly.

### Unaligned Checkpoints - Production Ready

Unaligned checkpoints now support adaptive triggering with timeouts which will only perform
unaligned checkpoint in case of backpressure and use aligned checkpoint otherwise. Thus, checkpoint
times become reliable in all situation while keeping extra state to a minimum.

Further, you can now rescale from unaligned checkpoints to provide more resources in case of sudden
spikes (together with reactive mode). This feature makes it easier to catch up and reduce
backpressure in a timely fashion.

Flink 1.13 brings together all features that the community initially envisioned for unaligned
checkpoints. Together with all bugfixes that happened in 1.12, we generally encourage the use of
unaligned checkpoints for all applications with potential backpressure.


### Machine Learning Library moving to a separate Repository

Flink’s ML development has been slowed down by too tight coupling of the ML efforts with the core
system.

ML will now follow the same approach as Stateful Functions and be developed as a separate library
with independent release cycles, but still under the umbrella of the Flink project.

---

## Table API/SQL

### Table-valued functions for Windows

Defining time windows is one of the most frequent operations in streaming SQL queries. We updated
the Flink SQL window syntax and semantics to be
closer to the SQL standard. This is in sync with other vendors in the industry by expressing windows
as a kind of table-valued functions.

TUMBLE and HOP windows have been ported to the new syntax. SESSION windows will follow in a
subsequent release. A new CUMULATE window function can assigns windows with an expanding step size
until the maximum window size is reached:

```sql
SELECT window_time, window_start, window_end, SUM(price) AS total_price 
  FROM TABLE(CUMULATE(TABLE Bid, DESCRIPTOR(bidtime), INTERVAL '2' MINUTES, INTERVAL '10' MINUTES))
GROUP BY window_start, window_end, window_time;
```

By referencing window start and window end of the table-valued window functions, it is now possible
to compute Top N windowed aggregations next to regular windowed aggregations and windowed joins:

```sql
SELECT window_time, ...
  FROM (
    SELECT *, ROW_NUMBER() OVER (PARTITION BY window_start, window_end ORDER BY total_price DESC) 
      as rank 
    FROM t
  ) WHERE rank <= 100;
```

### Improved interoperability between DataStream and Table API/SQL 

The Table API becomes equally important to the DataStream API which is why a good interoperability
between the two APIs is crucial. (FLIP-136): The core Row class has received a major update with new
toString/hash/equals methods. Fields can not only be accessed by position but also by name with
support of sparse representations. The new methods `StreamTableEnvironment.toDataStream/fromDataStream`
can model the DataStream API as a regular table source or sink with a smooth type system and event-time
integration.

```java
Table table=tableEnv.fromDataStream(
	dataStream,Schema.newBuilder()
	.columnByMetadata("rowtime","TIMESTAMP(3)")
	.watermark("rowtime","SOURCE_WATERMARK()")
	.build());

DataStream<Row> dataStream=tableEnv.toDataStream(table)
	.keyBy(r->r.getField("user"))
	.window(...)
```

### Improved SQL Client 

During the past releases, the SQL Client's feature set could not keep up with the evolution of the
TableEnvironment in the Table API. In this release, the SQL Client has been updated for feature
parity with the programmatic APIs.

*Easier Configuration and Code Sharing*

The support of YAML files to configure the SQL Client will be discontinued. Instead, the client
accepts one or more initialization scripts to configure an empty session. Additionally, a user can
declare a main SQL script for executing multiple statements in one file.

```
./sql-client.sh -i init1.sql init2.sql -f sqljob.sql
```

*More Commands and Support for Statement Sets*

For multi-statement execution, commands such as STATEMENT SET, and improved SET/RESET
commands with new config options have been added. The following example shows how a full SQL script
could be used as a command line tool to submit Flink jobs in a unified way for both batch and
streaming use cases:

```sql
-- set up a catalog
CREATE CATALOG hive_catalog WITH ('type' = 'hive');
USE CATALOG hive_catalog;

-- or use temporary objects
CREATE TEMPORARY TABLE clicks (
  user_id BIGINT,
  page_id BIGINT,
  viewtime TIMESTAMP
) WITH (
  'connector' = 'kafka',
  'topic' = 'clicks',
  'properties.bootstrap.servers' = '...',
  'format' = 'avro'
);

-- set the execution mode for jobs
SET execution.runtime-mode=streaming;

-- set the sync/async mode for INSERT INTOs
SET table.dml-sync=false;

-- set the job's parallelism
SET parallism.default=10;

-- set the job name
SET pipeline.name = my_flink_job;

-- restore state from the specific savepoint path
SET execution.savepoint.path=/tmp/flink-savepoints/savepoint-bb0dab;

BEGIN STATEMENT SET;

INSERT INTO pageview_pv_sink
SELECT page_id, count(1) FROM clicks GROUP BY page_id;

INSERT INTO pageview_uv_sink
SELECT page_id, count(distinct user_id) FROM clicks GROUP BY page_id;

END;
```

### Hive Query syntax compatibility

In order to improve Hive syntax compatibility, we introduced pluggable `Parser` to the planner
and added `HiveParser` for Hive dialect. In addition to DDL, Hive dialect now also supports
commonly-used Hive DML and DQL.

To use Hive dialect, set `table.sql-dialect` to `hive` as you do now, and also make sure to use
`HiveModule` since some syntax/semantic compatibility features rely on Hive built-in functions.
Following is an example of using Hive dialect:

```sql
CREATE CATALOG myhive WITH ('type' = 'hive'); -- setup HiveCatalog
USE CATALOG myhive;
LOAD MODULE hive; -- setup HiveModule
USE MODULES hive,core;
SET table.sql-dialect = hive; -- enable Hive dialect
SELECT key, value FROM src CLUSTER BY key; -- run some Hive queries
```
Note that Hive dialect no longer supports Flink syntax for DML and DQL. Switch to `default` dialect
when you need to write Flink syntax.

### Improved consistency of behavior between different SQL time functions**

Working with time is a crucial element of any data processing. Handling different time zones, dates and times
is one of the hardest tasks in working with data. In Flink 1.13. we put a lot of effort in simplifying the usage
of time related functions to make it a bit easier. We changed or made more specific return types of couple functions such as:
`PROCTIME()`, `CURRENT_TIMESTAMP`, `NOW()`.

Moreover, since Flink 1.13, you can also define event time attribute on TIMESTAMP_LTZ column. It means you can
gracefully do window processing with the support of the Daylight Saving Time.

Please see the release notes for a complete list of changes.

---

## PyFlink

### State access in DataStream API 
Stateful stream processing has always been a major differentiator for Apache Flink from other data
processing systems. While many operations in a
dataflow simply look at one individual event at a time (for example an event parser), some
operations remember information across multiple events (for example window operators). These
operations are called stateful.

The 1.12.0 release was the release when we reintroduced a rearchitected Python DataStream API, but
it is the access to State that comes in this release that fully opens up the full potential of
Apache Flink to Python users.

```python
class CountWindowAverage(FlatMapFunction):
    def __init__(self, window_size):
        self.window_size = window_size

    def open(self, runtime_context: RuntimeContext):
        descriptor = ValueStateDescriptor("average", Types.TUPLE([Types.LONG(), Types.LONG()]))
        self.sum = runtime_context.get_state(descriptor)

    def flat_map(self, value):
        current_sum = self.sum.value()
        if current_sum is None:
            current_sum = (0, 0)
        # update the count
        current_sum = (current_sum[0] + 1, current_sum[1] + value[1])
        # if the count reaches window_size, emit the average and clear the state
        if current_sum[0] >= self.window_size:
            self.sum.clear()
            yield value[0], current_sum[1] // current_sum[0]
        else:
            self.sum.update(current_sum)

ds = ...  # type: DataStream
ds.key_by(lambda row: row[0]) \
  .flat_map(CountWindowAverage(5))
```

### Window support in DataStream API

Windows are at the heart of processing infinite streams. Windows split the stream into “buckets” of finite size,
over which we can apply computations. In this release, the support of user-defined window was added in PyFlink
DataStream API.

### Row-based operations in Table API 

Every Flink release brings the Python Table API closer to a full feature parity with the Java API.
In this release, the support for row-based operations was added. Row-based operations take row as
input and returns row as output.

Following is an example of using map operation in Python Table API:
```python
@udf(result_type=DataTypes.ROW(
  [DataTypes.FIELD("c1", DataTypes.BIGINT()),
   DataTypes.FIELD("c2", DataTypes.STRING())]))
def my_map(r: Row) -> Row:
  return Row(r[0] + 1, r[1])

table = ...  # type: Table
mapped_result = table.map(my_map)
```

In addition to map, it also supports flat_map, aggregate, flat_aggregate, etc for row-based operations.

### Batch execution mode for PyFlink DataStream programs

In 1.12, it has added batch execution mode in the Java DataStream API. In this release, this feature
is also added in the Python DataStream API.

## Other improvements

**Flink Documentation via Hugo**

The Flink Documentation has been migrated from Jekyll to Hugo. If you find something missing, please let us know.
We are also curious to hear if you like the new look & feel.

**Exception histories in the Web UI**

From now on, the Flink Web UI will present up to n last exceptions that caused a job to fail.

**Better exception / failure-cause reporting for unsuccessful checkpoints**

Starting from the release Flink will provide statistics for checkpoints which failed or were
aborted. Prior versions were reporting metrics such as e.g. size of persisted data or trigger time
only in case a checkpoint succeeded. This change makes it easier to figure out a reason for the
failure without looking into logs.

**Exactly-once JDBC sink**

From 1.13, JDBC sink can guarantee exactly-once delivery for XA-compliant databases. That means no
data loss or duplication can occur in case of failover. Double processing (by Flink operators) can
still occur, but the result will only be delivered once.

The feature is available to DataStream programs via the new JdbcSink.exactlyOnceSink method (and
JdbcXaSinkFunction directly). The target database must be XA-compatible.

**General Python User-Defined Aggregate Function Support in group window of PyFlink Table API**

It supported both general Python UDAF and pandas UDAF in PyFlink Table API. In the previous releases,
The general Python UDAF could only be used in unbounded groupby aggregation. In this release,
it's also supported to be used in group window of PyFlink Table API.

**Improved performance of Sort-Merge Shuffles**

In 1.12, we introduced sort-merge blocking shuffle to Flink (FLIP-148). In this release the feature
was optimized to improve usability (fixed direct memory OOM issue) and performance (introduced IO
scheduling and broadcast optimization).

**HBase connector supports async lookup and lookup cache**

Before 1.13, HBase lookup source can only be used in sync mode which means the communication between
Flink and HBase is synchronous. This leads to poor throughput performance. In 1.13, we introduced
async lookup mode for HBase connector and also a lookup cache to reduce I/O interaction. This can
make Table/SQL jobs have much better throughput when lookup joining HBase.

## Change to consider when upgrading to Flink 1.13

* [FLINK-21709](https://issues.apache.org/jira/browse/FLINK-21709) - The old planner of the Table &
  SQL API has been deprecated in Flink 1.13 and will be dropped in Flink 1.14.
  The *Blink* engine has been the default planner for some releases now and will be the only one going forward.
  That means that both the `BatchTableEnvironment` and SQL/DataSet interoperability are reaching
  end of life. Please use the unified `TableEnvironment` for batch and stream processing going forward.
* [FLINK-22352](https://issues.apache.org/jira/browse/FLINK-22352) The community decided to deprecate
  the Apache Mesos support for Apache Flink. It is subject to removal in the future. Users are
  encouraged to switch to a different resource manager.
* [FLINK-21935](https://issues.apache.org/jira/browse/FLINK-21935) - The `state.backend.async`
  option is deprecated. Snapshots are always asynchronous now (as they were by default before) and
  there is no option to configure a synchronous snapshot anymore.
* [FLINK-17012](https://issues.apache.org/jira/browse/FLINK-17012) - The tasks' `RUNNING` state was split
  into two states: `INITIALIZING` and `RUNNING`. A task is `INITIALIZING` while it loads the checkpointed state,
  and, in the case of unaligned checkpoints, until the checkpointed in-flight data has been recovered.
  This lets monitoring systems better determine when the tasks are really back to doing work, by making
  the phase for state restoring explicit.
* [FLINK-21698](https://issues.apache.org/jira/browse/FLINK-21698) - The *CAST* operation between the
  NUMERIC type and the TIMESTAMP type is problematic and therefore no longer supported: Statements like 
  `CAST(numeric AS TIMESTAMP(3))` will now fail. Please use `TO_TIMESTAMP(FROM_UNIXTIME(numeric))` instead.
* [FLINK-22133](https://issues.apache.org/jira/browse/FLINK-22133) The unified source API for connectors
  has a minor breaking change: The `SplitEnumerator.snapshotState()` method was adjusted to accept the
  *Checkpoint ID* of the checkpoint for which the snapshot is created.

## Resources

The binary distribution and source artifacts are now available on the updated [Downloads page]({{ site.baseurl }}/downloads.html)
of the Flink website, and the most recent distribution of PyFlink is available on [PyPI](https://pypi.org/project/apache-flink/).

Please review the [release notes]({{ site.DOCS_BASE_URL }}flink-docs-release-1.13/release-notes/flink-1.13.html)
carefully if you plan to upgrade your setup to Flink 1.13. This version is API-compatible with
previous 1.x releases for APIs annotated with the `@Public` annotation.

You can also check the complete [release changelog](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&version=12349287) 
and [updated documentation]({{ site.DOCS_BASE_URL }}flink-docs-release-1.13/) for a detailed list of changes and new features.

## List of Contributors

The Apache Flink community would like to thank each one of the contributors that have
made this release possible:

acqua.csq, AkisAya, Alexander Fedulov, Aljoscha Krettek, Ammar Al-Batool, Andrey Zagrebin, anlen321,
Anton Kalashnikov, appleyuchi, Arvid Heise, Austin Cawley-Edwards, austin ce, azagrebin, blublinsky,
Brian Zhou, bytesmithing, caozhen1937, chen qin, Chesnay Schepler, Congxian Qiu, Cristian,
cxiiiiiii, Danny Chan, Danny Cranmer, David Anderson, Dawid Wysakowicz, dbgp2021, Dian Fu,
DinoZhang, dixingxing, Dong Lin, Dylan Forciea, est08zw, Etienne Chauchot, fanrui03, Flora Tao,
FLRNKS, fornaix, fuyli, George, Giacomo Gamba, GitHub, godfrey he, GuoWei Ma, Gyula Fora,
hackergin, hameizi, Haoyuan Ge, Harshvardhan Chauhan, Haseeb Asif, hehuiyuan, huangxiao, HuangXiao,
huangxingbo, HuangXingBo, humengyu2012, huzekang, Hwanju Kim, Ingo Bürk, I. Raleigh, Ivan, iyupeng,
Jack, Jane, Jark Wu, Jerry Wang, Jiangjie (Becket) Qin, JiangXin, Jiayi Liao, JieFang.He, Jie Wang,
jinfeng, Jingsong Lee, JingsongLi, Jing Zhang, Joao Boto, JohnTeslaa, Jun Qin, kanata163, kevin.cyj,
KevinyhZou, Kezhu Wang, klion26, Kostas Kloudas, kougazhang, Kurt Young, laughing, legendtkl,
leiqiang, Leonard Xu, liaojiayi, Lijie Wang, liming.1018, lincoln lee, lincoln-lil, liushouwei,
liuyufei, LM Kang, lometheus, luyb, Lyn Zhang, Maciej Obuchowski, Maciek Próchniak, mans2singh,
Marek Sabo, Matthias Pohl, meijie, Mika Naylor, Miklos Gergely, Mohit Paliwal, Moritz Manner,
morsapaes, Mulan, Nico Kruber, openopen2, paul8263, Paul Lam, Peidian li, pengkangjing, Peter Huang,
Piotr Nowojski, Qinghui Xu, Qingsheng Ren, Raghav Kumar Gautam, Rainie Li, Ricky Burnett, Rion
Williams, Robert Metzger, Roc Marshal, Roman, Roman Khachatryan, Ruguo,
Ruguo Yu, Rui Li, Sebastian Liu, Seth Wiesman, sharkdtu, sharkdtu(涂小刚), Shengkai, shizhengchao,
shouweikun, Shuo Cheng, simenliuxing, SteNicholas, Stephan Ewen, Suo Lu, sv3ndk, Svend Vanderveken,
taox, Terry Wang, Thelgis Kotsos, Thesharing, Thomas Weise, Till Rohrmann, Timo Walther, Ting Sun,
totoro, totorooo, TsReaper, Tzu-Li (Gordon) Tai, V1ncentzzZ, vthinkxie, wangfeifan, wangpeibin,
wangyang0918, wangyemao-github, Wei Zhong, Wenlong Lyu, wineandcheeze, wjc, xiaoHoly, Xintong Song,
xixingya, xmarker, Xue Wang, Yadong Xie, yangsanity, Yangze Guo, Yao Zhang, Yuan Mei, yulei0824, Yu
Li, Yun Gao, Yun Tang, yuruguo, yushujun, Yuval Itzchakov, yuzhao.cyz, zck, zhangjunfan,
zhangzhengqi3, zhao_wei_nan, zhaown, zhaoxing, Zhenghua Gao, Zhenqiu Huang, zhisheng, zhongqishang,
zhushang, zhuxiaoshang, Zhu Zhu, zjuwangg, zoucao, zoudan, 左元, 星, 肖佳文, 龙三

